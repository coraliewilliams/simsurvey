---
title: "Current Practices of Simulation Studies for Statistical Method Evaluation in Ecology and Evolutionary Biology"
#author: "Coralie Williams, Yefeng Yang, Malgorzata Lagisz, Kyle Morrison, Lorenzo Ricolfi, David Warton, and Shinichi Nakagawa"
date: "Last compiled on `r format(Sys.time(), '%d %B, %Y')`"
format:
  html:
    toc: true
    toc-location: left
    toc-depth: 2
    theme: sandstone
    embed-resources: true
    code-fold: show
    code-tools: true
    number-sections: true
editor_options: 
  chunk_output_type: console
---

This study surveyed 100 research articles in ecology and evolution journals that included simulation studies evaluating statistical methods. The following HTML webpage provides the code necessary to reproduce the analysis detailed in the paper.

The code is written in R (R Core Team, 2023) and is designed to be run with installation of the R packages listed in the *Load packages* section of the code with versions specified in the *Session information* section.

**Load packages**

```{r setup}
#| output: false
#| warning: false
#| label: packages
#| code-overflow: wrap
#| code-fold: true

pacman::p_load(
  rmarkdown,
  readr,
  dplyr,
  purrr,
  splitstackshape,
  tidyverse,
  tidyr,
  ggplot2,
  vroom,
  details,
  sessioninfo,
  devtools,
  readxl,
  forcats,
  stringr,
  RColorBrewer,
  patchwork,
  kableExtra
)

options(digits = 3, scipen = 5)
```

# Literature search

## Journal list

```{r journalList, warning=F, message=F}
# Load journal lists
jcr_eco <- read_csv("~/Projects/simsurvey/data/JCR/JCR_JournalResults_09_2022_Ecology.csv", skip = 2)
jcr_evo <- read_csv("~/Projects/simsurvey/data/JCR/JCR_JournalResults_09_2022_Evolutionary_Biology.csv", skip = 2)

# Cleanup: delete empty rows and comment lines at the end of files
jcr_eco <- jcr_eco[which(!is.na(jcr_eco$ISSN)),]
jcr_evo <- jcr_evo[which(!is.na(jcr_evo$ISSN)),]


# Check how many journals overlap between each journal group: none with stats journal list, and 18 journals between eco and evo
eco_in_evo <- jcr_eco$`Journal name`[which(jcr_eco$`Journal name` %in% jcr_evo$`Journal name`)]
evo_in_eco <- jcr_evo$`Journal name`[which(jcr_evo$`Journal name` %in% jcr_eco$`Journal name`)]

# get concatenated list of eco + evo journal lists
ecoevo <- rbind(jcr_eco, jcr_evo)

## change in code below on 20/09/2023, before this code was merging on all columns and only matched 15 journals and missed 3 journals that were overlapping due to different values in "JIF Quartile" column

# get list of matching and unique journals between eco and evo groups
ecoevo_match <- merge(jcr_eco[,-c(5,8)], jcr_evo[,-c(5,8)], by=c("Journal name","JCR Abbreviation", "ISSN", "eISSN", "Total Citations", "2021 JIF", "2021 JCI", "% of OA Gold"))
ecoevo_match$Category <- "Both"
ecoevo_match$`JIF Quartile` <- "NA"
ecoevo_notmatch <- ecoevo[which(!ecoevo$`Journal name` %in% ecoevo_match$`Journal name`),]

# get merged list of journals from eco and evo
ecoevo_merged <- rbind(ecoevo_match, ecoevo_notmatch)

# save results
write_csv(ecoevo_merged, "~/Projects/simsurvey/data/ecoevo_jcr_journal_list.csv", na="")

```

## Search strings

The custom search string was developed on 13/10/2022 on Web of Science

::: {.callout-tip appearance="minimal" icon="false"}
**(TS=((simulation\*) AND ("method") AND ("compar" OR "evaluat" OR "validat" OR "statist") AND (bias OR coverag\* OR power OR convergence OR"standard error" OR "confidence interval" OR "performance measure" OR "mean error" OR "type I error"))) AND WC=("Ecology" OR "Evolutionary Biology"**
:::

## Inclusion criteria

-   Include publications between 01-01-2018 and 01-10-2022.
-   Include studies using simulation for the evaluation of statistical methodologies.
-   Included studies published in one of predefined journals in ecology or evolutionary biology.
-   Include if full text is available.
-   Include if full text is in English.

## Exclusion criteria

-   Exclude simulation studies that are part of a review, commentary, letter to the editor or tutorial (for example: <https://doi.org/10.1111/ecog.04385>).
-   Exclude simulation studies that are not evaluating statistical methods (for example simulation studies to assess ecological theories: <https://doi.org/10.1016/j.ecolmodel.2019.02.007>).
-   Exclude simulation studies that are used to solely analyse data e.g. Monte Carlo Markov Chain (MCMC) simulations.
-   Exclude simulation studies who are not the main part of the paper.

::: column-margin
Note, full decision tree with inclusion and exclusion criteria are provided in Supporting Information 1.
:::


Five articles were added post-hoc to the search and screening to reach 100 articles.

```{r}
# import rayyan decision of 50 papers screening
rayyan_50papers <- read.csv("~/Projects/simsurvey/data/survey/rayyan_abstract_results_50papers.csv")

# randomly sample 5 papers from included list
set.seed(48)
extra_5papers <- rayyan_50papers %>% 
  filter(grepl("Included", notes)) %>% 
  sample_n(5)

# Pseudo-randomly sample one more paper as one paper from the 5 randomly sampled did not meet inclusion criteria in full-text (Wu et al., 2019: is not a simulation study)
set.seed(48)
extra_6papers <- rayyan_50papers %>% 
  filter(grepl("Included", notes)) %>% 
  sample_n(6)

```

# Analysis

```{r}
# Load text extraction
survey_raw <- read_excel("~/Projects/simsurvey/data/survey/simulationSurvey_extraction_100papers.xlsx", na=c("", "NA", NA))
# remove questions that are comments
survey <- survey_raw %>% select(!matches("comment"))

```


### Literature search results

```{r}
# make year as factor
journal_count <- as.data.frame(table(survey$journal))
journal_count <- journal_count %>% 
  select(Journal="Var1",Freq="Freq") %>%
  arrange(desc(Freq))
kable(journal_count)

# make year as factor
survey$paper_year <-  as.factor(survey$paper_year)

# plot histogram
ggplot(survey, aes(x = paper_year)) +
  geom_bar(aes(fill = paper_year)) +
  xlab("") +
  ylab("Count") +
  ggtitle("Publication year") +
  scale_fill_manual(values=rep("lightblue",6)) +
  scale_y_continuous(breaks = seq(0, 28, by = 5), limits = c(0, 28)) +
  theme(
    axis.text.x = element_text(angle = 40, hjust=1, size = 12), 
    axis.text.y = element_text(size = 12),  
    axis.title.x = element_text(size = 12), 
    axis.title.y = element_text(size = 12), 
    panel.background = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.major.y = element_line(color = "grey50"),
    panel.grid.minor.y = element_line(color = "grey50")
  ) + theme(legend.position="none")

```

## Reporting results

The following questions were focused on simulation studies reporting quality:

`1.1.aims_reporting` Are the aims of the simulation defined?

`2.1.datagen_reporting` Is the data-generating mechanisms described?

`2.4.datagen_informed` Are the specifications of the data-generating mechanisms informed (i.e. justified with a reference or narrative justification)?

`3.1.estimandtarget_reporting` Were the estimand(s), statistical target and task of the simulation study described?

`4.1.method_reporting` Is the study citing other relevant statistical methodology literature on the topic?

`5.1.perfmeasures_reporting` Were all performance measures planned to be investigated defined or described?

`5.3.perfmeasures_lessknown` If a performance measure planned to be used is less-known, was the formula given explicitly?

`6.1.software_reporting` Is/Are all software(s) and all package(s) used in the simulation study reported explicitly?

`6.4.software_Rpackage` If R statistical software was used, were the packages that were used reported?

`7.1.code_datagen` Is the code to execute the simulation study made available?

`7.2.code_datagen_allsteps` Does the code include data generating and analysis simulation steps?

`8.1.code_perfmeasures` Is the code to obtain performance measures made available?


```{r}

# Store 12 reporting questions -------------------
r <- c("1.1.aims_reporting", 
       "2.1.datagen_reporting", 
       "3.1.estimandtarget_reporting",
       "4.1.method_reporting",
       "5.1.perfmeasures_reporting",
       "5.3.perfmeasures_lessknown",
       "6.1.software_reporting",
       "6.4.software_Rpackage",
       "7.1.code_datagen",
       "7.2.code_datagen_allsteps",
       "8.1.code_perfmeasures",
       "10.1.analysis_perfmeasures_reporting")

r_labels <- c("1.aims", 
              "2.data generation mechanisms", 
              "3.estimand/target",
              "4.method",
              "5.performance measures",
              "5.performance measures less known",
              "6.software",
              "6.software package",
              "7.code for data generation",
              "7.code for all simulation steps",
              "8.code for performance measures",
              "10.analysis in graphical or tabular form")


# only planning stage 
r1 <- c("1.1.aims_reporting", 
       "2.1.datagen_reporting", 
       "3.1.estimandtarget_reporting",
       "4.1.method_reporting",
       "5.1.perfmeasures_reporting")

# only coding stage
r2 <- c("6.1.software_reporting")

# only analysis stage
r3 <- c("9.1.analysis_exploratory",
       "10.1.analysis_perfmeasures_reporting",
       "11.1.analysis_montecarlo_uncertainty")


# Store 12 reporting-section questions ------------
rs <- c("1.2.aims_reportingsection", 
        "2.2.datagen_reportingsection", 
        "2.5.2.datagen_parameters_section",
        "2.6.2.datagen_conditions_section",
        "2.7.2.datagen_simulationruns_section",
        "3.2.estimandtarget_reportingsection",
        "4.2.method_reportingsection",
        "5.2.perfmeasures_reportingsection",
        "6.2.software_reportingsection",
        "9.2.analysis_exploratory_reporting",
        "10.2.analysis_perfmeasures_reportingsection",
        "11.2.analysis_montecarlo_reportingsection")

rs_labels <- c("1.aims", 
          "2.data generation mechanisms", 
          "2.data gen. no. of parameters",
          "2.data gen. no. of conditions",
          "2.data gen. no. of simulation runs",
          "3.estimand/target",
          "4.method",
          "5.performance measures",
          "6.software",
          "9.analysis with a case study",
          "10.analysis in graphical or tabular form",
          "11.analysis monte carlo uncertainty")

# only planning stage
rs1 <- c("1.2.aims_reportingsection", 
        "2.2.datagen_reportingsection", 
        "3.2.estimandtarget_reportingsection",
        "4.2.method_reportingsection",
        "5.2.perfmeasures_reportingsection")

# coding stage
rs2 <- c("6.2.software_reportingsection")

# analysis stage
rs3 <- c("9.2.analysis_exploratory_reporting",
        "10.2.analysis_perfmeasures_reportingsection",
        "10.1.analysis_perfmeasures_reporting",
        "11.2.analysis_montecarlo_reportingsection")

```


```{r}

# Function to make horizontal histogram of reporting descripton + reporting section questions
create_plot <- function(survey, r_vector, title, labels) {
  
  # select columns of interest
  r_long <- survey %>% 
    select(all_of(r_vector)) %>%
    pivot_longer(cols = everything())
  
  # summarise by name and value
  count_r <- r_long %>% 
    group_by(name, value) %>% 
    count()

  # get the total number per category
  count_r <- count_r %>% 
    group_by(name) %>% 
    mutate(total=sum(n))
  
  # get percentages
  percent_r <- count_r %>% 
    mutate(proportion = n/total,
           percentage = proportion * 100)

  # rename and reorder labels of questions
  percent_r$name <- plyr::mapvalues(percent_r$name, from=r_vector, to=labels)
  percent_r$name <- factor(percent_r$name, levels=rev(labels))
  percent_r$value <- replace_na(percent_r$value, "N.A.")
  percent_r$value <- factor(percent_r$value, levels=c("N.A.", "No", "Yes"))

  # make ggplot
  ggplot(data = percent_r, aes(x = name, y = percentage, fill = value)) +
    geom_col(width = 0.7, color = "black") +
    coord_flip(ylim = c(0, 100)) +
    scale_fill_manual(values = c("N.A."="white", "No"="#713979", "Yes"="#4DAF4A"),
                      guide = guide_legend(reverse = TRUE)) +
    theme(legend.position = "bottom", 
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank()) +
    ggtitle(title) +
    theme(axis.text.x = element_text(size=14))  +
    theme(axis.text.y = element_text(size=14))  +
    ylab("Percentage (%)") +
    xlab("Survey question")
}

# Apply the function to each question group
supp1 <- create_plot(survey, r, "Reporting description", labels=r_labels)

# Plot the figures
print(supp1)

```

## Reporting section results

The following questions were focused on simulation studies reporting section:

`1.2.aims_reportingsection` Are the aims of the simulation study defined in the Introduction or Methods section?

`2.2.datagen_reportingsection` Is the data-generating mechanisms described in the Methods section?

`2.5.2.datagen_parameters_section` Are the varying parameters reported explicitly in the Methods section?

`2.6.2.datagen_conditions_section` Are the number of conditions reported explicitly in the Methods section?

`2.7.2.datagen_simulationruns_section` Are the number simulation runs reported explicitly in the Methods section?

`3.2.estimandtarget_reportingsection` Is/Are the estimands or statistical targets/task described in the Methods section?

`4.2.method_reportingsection` Is the study citing other relevant statistical methodology in the Introduction and/or Methods?

`5.2.perfmeasures_reportingsection` Were performance measures planned to be investigated defined or described in the Methods section?

`6.2.software_reportingsection` Were the software(s) and package(s) used in the simulation study reported in Methods or Results section?

`9.2.analysis_exploratory_reporting` Was a working example or case study reported in the Results or Supplementary Material section?

`10.2.analysis_perfmeasures_reportingsection` Were all performance measures results reported in the Results or Supplementary Material?

`11.2.analysis_montecarlo_reportingsection` Are Monte Carlo error reported in the Results or Supplementary Material section?

```{r}

# Apply the function to each question group
supp2 <- create_plot(survey, rs, "Reporting section", rs_labels)

# Plot the figures
print(supp2)

# Make plot for main text
Figure_ReportingPractices <- supp1 / supp2 +
  plot_annotation(tag_levels = 'A')

# save 
ggsave("output/Figure_ReportingPractices_allStages.png", Figure_ReportingPractices,
       width = 11, height = 9, dpi = 400, units = "in", bg = "transparent")

``` 

## Characteristics results

The following questions were focused on simulation studies characteristics:

**Planning stage**

`1.3.aims_purpose` What is the purpose of the simulation study?

`2.3.datagen_type` What type of data-generating mechanism was used?

`2.4.datagen_informed` Are the specifications of the data-generating mechanisms informed?

`2.5.1.datagen_parameters` How many varying parameters were used in data-generating mechanisms?

`2.6.1.datagen_conditions` How many conditions were used in total in the simulation study? (varying parameter combination)

`2.7.1.datagen_simulationruns` What is the number of simulation runs performed? (report the maximum number used)

`2.7.3.datagen_simulationruns_justification` Was the number simulation runs justified?

`2.8.datagen_distribution` If a parametric model was used, what was/were the distribution type(s) used?

`3.3.estimandtarget_type` What is/are the estimands or statistical targets/task of the simulation study?

`4.3.method_type` What is the simulation study evaluating?

`5.4.perfmeasures` What performance measure(s) were planned to be investigated in the simulation study?

```{r}
###### 1: Aims --------------------------------------------------------------------------------

#table(survey$`1.3.aims_purpose`, useNA = "ifany")

# Save aims response as separate vector
aims_purpose <- survey$`1.3.aims_purpose`

#  Format the vector into a dataframe
aims_dat <- data.frame(AimsPurpose = aims_purpose) %>%
  mutate(category = case_when(
    AimsPurpose=="Evaluating analytical method" ~ "Analytical\n method",
    AimsPurpose=="Designing and/or planning of study" ~ "Study\n design",
    AimsPurpose=="Both"|AimsPurpose=="Designing and/or planning of study;Evaluating analytical method" ~ "Both"
    )) %>%
  group_by(category) %>%
  summarise(counts = n()) %>%
  mutate(percentage = counts / sum(counts) * 100)

# Plot histogram with ordered categories
plot_aims <- ggplot(aims_dat, aes(x = reorder(category, -counts), y = counts, fill = category)) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal() +
  scale_y_continuous(breaks = seq(0, 80, by = 10)) +
  #coord_flip() + 
  labs(title = "Aims and Purposes", x = "", y = "Percentage (%)\n") +
  theme(axis.title.y = element_text(size=14)) +
  theme(axis.text.x = element_text(size=14))  +
  theme(axis.text.y = element_text(size=14)) +
  theme(legend.position = "none") +
  coord_fixed(ratio=0.04)
plot_aims

```

```{r}
###### 2: Data-generating mechanism ----------------------------------------------------------------

####### Data-generating Type #######

#table(survey$`2.3.datagen_type`, useNA = "ifany")

# save data-generation type as separate vector
datgen_type <- survey$`2.3.datagen_type`

# Format the vector into a dataframe and clean up the categories
datgen_type <- data.frame(Type=datgen_type) %>%
  mutate(Type = case_when(
           Type == "Parametric model (\"known\");Resampling method (\"unknown\")" ~ "Both",
           grepl("Parametric model", Type, ignore.case = T) ~ "Parametric",
           grepl("Resampling method", Type, ignore.case = T) ~ "Resampling",
           TRUE ~ "NA"
         ))

# Derive the counts and percentages
datgen_type_summary <- datgen_type %>%
  group_by(Type) %>%
  summarise(counts = n()) %>%
  mutate(Percentage = counts / sum(counts) * 100) %>% 
  arrange(desc(counts)) %>%
  mutate(Type = factor(Type, levels = unique(Type))) 


# Plot histogram of data-generation type
plot_datgen <- ggplot(datgen_type_summary, aes(x = reorder(Type, -counts), y = counts, fill = Type)) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal() +
  #coord_flip() +
  labs(title = "Data-generating type", x = "", y = "Percentage (%)\n") +
  theme(axis.title.y = element_text(size=14)) +
  scale_y_continuous(breaks = seq(0, 80, by = 10)) +
  theme(axis.text.x = element_text(size=14, angle=45, hjust=1))  +
  theme(axis.text.y = element_text(size=14))  +
  theme(legend.position = "none") +
  coord_fixed(ratio=0.04)
plot_datgen


####### Data-generating parameters justified #######

#table(survey$`2.4.datagen_informed`, useNA = "ifany")
#
# save data-generation type as separate vector
datgen_inform <- survey$`2.4.datagen_informed`
datgen_inform <- data.frame(datgen_inform)

# Derive the counts and percentages
datgen_inform_summary <- datgen_inform %>%
  group_by(datgen_inform) %>%
  summarise(counts = n()) %>%
  mutate(Percentage = counts / sum(counts) * 100) %>% 
  arrange(desc(counts)) %>%
  mutate(datgen_inform = factor(datgen_inform, levels = unique(datgen_inform))) 


# Plot histogram of data-generation type
ggplot(datgen_inform_summary, aes(x = reorder(datgen_inform, counts), y = counts, fill = datgen_inform)) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal() +
  coord_flip() +
  labs(title = "Data-generating justification", x = "", y = "counts")  +
  theme(axis.text.x = element_text(size=14))  +
  theme(axis.text.y = element_text(size=14))


####### Parameters, conditions and runs #######

##### Number of parameters
par_mean <- mean(survey$`2.5.1.datagen_parameters`, na.rm=T)
par_min <- min(survey$`2.5.1.datagen_parameters`, na.rm=T)
par_max <- max(survey$`2.5.1.datagen_parameters`, na.rm=T)
par_median <- median(survey$`2.5.1.datagen_parameters`, na.rm=T)

# Set up data to plot
datgen_pars <- data.frame(pars=survey$`2.5.1.datagen_parameters`)
datgen_pars_clean <- na.omit(datgen_pars)
# histogram of number of parameters
plot_pars <- ggplot(datgen_pars_clean, aes(x=pars)) +
  geom_histogram(binwidth = 1, colour = "deepskyblue4", fill = "skyblue") +
  scale_x_continuous(breaks = seq(0, 14, by = 1)) +
  scale_y_continuous(breaks = seq(0, 28, by=2)) +
  theme_minimal() +
  theme(axis.text.x = element_text(size=14)) +
  theme(axis.text.y = element_text(size=14)) +
  labs(title = "Number of simulated parameters", x = "No. parameters", y = "frequency")
plot_pars



###### Number of conditions
cond_mean <- mean(survey$`2.6.1.datagen_conditions`, na.rm=T)
cond_min <- min(survey$`2.6.1.datagen_conditions`, na.rm=T)
cond_max <- max(survey$`2.6.1.datagen_conditions`, na.rm=T)
cond_med <- median(survey$`2.6.1.datagen_conditions`, na.rm=T)

# Set up data to plot
datgen_cond <- data.frame(cond=survey$`2.6.1.datagen_conditions`)
datgen_cond_clean <- na.omit(datgen_cond)
# make conditions as factor
datgen_cond_clean$cond <- as.factor(datgen_cond_clean$cond)
# histogram number of conditions
plot_conds <- ggplot(datgen_cond_clean, aes(x=cond)) +
  geom_bar(colour = "deepskyblue4", fill = "skyblue") +
  theme_minimal() +
  scale_y_continuous(breaks = seq(0, 6, by = 1)) +
  #coord_flip() +
  theme(axis.text.x = element_text(size=11, angle=45, hjust=1)) +
  theme(axis.text.y = element_text(size=12)) +
  labs(title = "Number of simulation conditions", x = "No. conditions", y = "frequency")
plot_conds



###### Number of simulation runs
survey$`2.7.1.datagen_simulationruns` <- as.numeric(survey$`2.7.1.datagen_simulationruns`)
runs_mean <- mean(survey$`2.7.1.datagen_simulationruns`, na.rm=T)
runs_min <- min(survey$`2.7.1.datagen_simulationruns`, na.rm=T)
runs_max <- max(survey$`2.7.1.datagen_simulationruns`, na.rm=T)

runs_med <- median(survey$`2.7.1.datagen_simulationruns`, na.rm=T)


# Set up data to plot
datgen_runs <- data.frame(runs=survey$`2.7.1.datagen_simulationruns`)
datgen_runs$runs <- as.factor(datgen_runs$runs)
# histogram of number of simulation runs
plot_simruns <- ggplot(datgen_runs, aes(x=runs)) +
  geom_bar(colour = "deepskyblue4", fill = "skyblue") +
  scale_y_continuous(breaks = seq(0,28, by=5)) +
  theme_minimal() +
  #coord_flip() +
  theme(axis.text.x = element_text(size=13,angle=45, hjust=1)) +
  theme(axis.text.y = element_text(size=14)) +
  labs(title = "Number of simulation runs", x = "No. runs", y = "frequency")
plot_simruns



```

```{r}

####### Distribution #######

#table(survey$`2.8.datagen_distribution`)
dist_vector <- survey$`2.8.datagen_distribution`

# Format the vector into a dataframe and clean up the categories
dist_new <- data.frame(Distribution=dist_vector) %>%
  separate_rows(Distribution, sep = ";|,") %>%
  mutate(Distribution = trimws(Distribution),
         Distribution = case_when(
           grepl("normal", Distribution, ignore.case = T) ~ "Normal",
           grepl("binomial", Distribution, ignore.case = T) ~ "Binomial",
           grepl("poisson", Distribution, ignore.case = T) ~ "Poisson",
           grepl("negative binomial", Distribution, ignore.case = T) ~ "Negative Binomial",
           grepl("uniform", Distribution, ignore.case = T) ~ "Uniform",
           grepl("exponential", Distribution, ignore.case = T) ~ "Exponential",
           grepl("gamma", Distribution, ignore.case = T) ~ "Gamma",
           grepl("dirichlet", Distribution, ignore.case = T) ~ "Dirichlet",
           grepl("No parametric distribution used", Distribution, ignore.case = T) ~ "Non parametric",
           TRUE ~ "Other"
         ))

# Derive the counts and percentages
dist_summary <- dist_new %>%
  group_by(Distribution) %>%
  summarise(counts = n()) %>%
  mutate(Percentage = counts / sum(counts) * 100) %>% 
  arrange(desc(counts)) %>%
  mutate(Distribution = factor(Distribution, levels = unique(Distribution))) 


# Plot histogram
plot_dist <- ggplot(dist_summary, aes(x = Distribution, y = counts, fill = Distribution)) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal() +
  scale_y_continuous(breaks = seq(0,50, by=5)) +
  labs(title = "Statistical Distributions", x = "", y = "Percentage (%)\n") +
  theme(axis.title.y = element_text(size=14)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size=14)) +
  theme(axis.text.y = element_text(size=14)) +
  theme(legend.position = "none")

plot_dist


```

```{r}

###### 3: Estimand/Target ----------------------------------------------------------

# Estimand/target were counted for each time it was mentioned across all studies 

#table(survey$`3.3.estimandtarget_type`)

# Split the entries and unlist into a single vector 
estimand_list <- unlist(strsplit(survey$`3.3.estimandtarget_type`, ";"))
estimand_counts <- table(estimand_list)

# order the counts in decreasing order
estimand_counts <- estimand_counts[order(estimand_counts, decreasing = TRUE)]
estimand_counts <- as.data.frame(estimand_counts)

# rename categories of estimand_list variable
estimand_counts <- estimand_counts %>%
  mutate(estimand_list = case_when(
    estimand_list=="Estimand (estimation)" ~ "Estimation",
    estimand_list=="Null hypothesis (hypothesis testing)" ~ "Hypothesis \ntesting",
    estimand_list=="Selected design (study design)" ~ "Study design",
    estimand_list=="Predictions (prediction)" ~ "Prediction",
    estimand_list=="Model (model selection)" ~ "Model selection"
  ))


# Plot histogram
plot_estarget <- ggplot(estimand_counts, aes(x = reorder(estimand_list, -Freq), y = Freq, fill = estimand_list)) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal() +
  #coord_flip() +
  labs(title = "Statistical target", x = "", y = "Percentage (%)\n") +
  theme(axis.title.y = element_text(size=14)) +
  scale_y_continuous(breaks = seq(0,70, by=10)) +
  theme(axis.text.x = element_text(size=14, angle=45, hjust=1)) +
  theme(axis.text.y = element_text(size=14)) +
  theme(legend.position = "none")
plot_estarget



###### 4: Method -------------------------------------------------------------------

# counts per category
method_type <- table(survey$`4.3.method_type`)

# order the counts in decreasing order
method_type <- method_type[order(method_type, decreasing = TRUE)]
method_type <- as.data.frame(method_type)

# rename Var1 categories
method_type <- method_type %>%
  mutate(Var1 = case_when(
    Var1=="Existing method(s)" ~ "Existing",
    Var1=="New method or procedure" ~ "New method",
    Var1=="Both (e.g. for comparison purposes)" ~ "Both",
    Var1=="Study design" ~ "Study design"
  ))

# Plot histogram
plot_method <- ggplot(method_type, aes(x = reorder(Var1, -Freq), y = Freq, fill = Var1)) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal() +
  #coord_flip() +
  labs(title = "Method type", x = "", y = "Percentage (%)\n") +
  theme(axis.text.x = element_text(size=14, angle=45, hjust=1)) +
  theme(axis.text.y = element_text(size=14)) +
  theme(axis.title.y = element_text(size=14)) +
  scale_y_continuous(breaks = seq(0,70, by=5), limits=c(0,55)) +
  theme(legend.position = "none") +
  coord_fixed(0.08)

plot_method



###### 5: Performance measures -----------------------------------------------------

perf_measures <- survey$`5.4.perfmeasures`

# Obtained data frame with all single entried of performance measures
perf_dat <- data.frame(PerfMeasures = perf_measures) %>%
  # Separate entries by ";" or ","
  separate_rows(PerfMeasures, sep = ";|,") %>%
  # Clean up category names into specified categories
  mutate(category = case_when(
    grepl("Bias", PerfMeasures, ignore.case = TRUE) ~ "Bias",
    grepl("Mean squared error|MSE|relative standard error", PerfMeasures, ignore.case = TRUE) ~ "Mean squared \nerror (MSE)",
    grepl("Confidence interval length|width", PerfMeasures, ignore.case = TRUE) ~ "Confidence \ninterval width",
    grepl("Precision|coefficient of variation|Coefficient of variance", PerfMeasures, ignore.case = TRUE) ~ "Precision",
    grepl("Power", PerfMeasures, ignore.case = TRUE) ~ "Power",
    grepl("Type I|Type II", PerfMeasures, ignore.case = TRUE) ~ "Type I or II error",
    grepl("false positive rate|false negative rate|TPR|TNR|FPR|FNR|classification rate|positive predictive value| misclassification|error rate", PerfMeasures, ignore.case = TRUE) ~ "Classification \nrate",
    grepl("Coverage", PerfMeasures, ignore.case = TRUE) ~ "Coverage",
    #grepl("Accuracy", PerfMeasures, ignore.case = TRUE) ~ "Accuracy",
    grepl("Accuracy", PerfMeasures, ignore.case = TRUE)|is.na(PerfMeasures) ~ "Not reported \nor unclear",
    TRUE ~ "Other"
  )) %>%
  # Derive the counts for each category and the overall percentage
  group_by(category) %>%
  summarise(counts = n()) %>%
  mutate(percentage = counts / sum(counts) * 100) %>%
  ungroup() %>%
  # Arrange by Counts descending for plotting
  arrange(desc(counts))  %>%
  mutate(category = factor(category, levels = unique(category))) 



# Plot histogram with ordered categories
plot_perf <- ggplot(perf_dat, aes(x = reorder(category, -counts), y = counts, fill = category)) +
  geom_bar(stat = "identity") +
  #fill=c(rep("skyblue",8),"#d9700f","skyblue")
  theme_minimal() +
  scale_fill_brewer(palette = "Set3") +
  labs(title = "Performance Measure", x = "", y = "Percentage (%)\n") +
  #coord_flip() +
  scale_y_continuous(breaks = seq(0,55, by=5)) +
    theme(axis.title.y = element_text(size=14)) +
  theme(axis.text.x = element_text(size=14, angle = 45, vjust = 1, hjust=1)) +
  theme(axis.text.y = element_text(size=14)) +
  theme(legend.position = "none")
  
plot_perf 

```

```{r}
####################################
##### Save plots for main text #####
####################################


###### Figure 3: overall characteristics 
Figure_Characteristics <- (plot_aims | plot_datgen) /
  (plot_dist | plot_estarget) /
  (plot_method | plot_perf) +
  plot_annotation(tag_levels = 'A') 

# save for manuscript
ggsave("output/Figure_Characteristics.png", Figure_Characteristics,
       width = 11, height = 14, units = "in", dpi = 400)


####### Figure 4: data-generating mechanisms summary 
Figure_DataGenMech <- (plot_pars | plot_simruns) / plot_conds +
  plot_annotation(tag_levels = 'A') 

# save for manuscript
ggsave("output/Figure_DataGenMech.png", Figure_DataGenMech ,
       width = 10, height = 10, units = "in", dpi = 400)

```


```{r}
##################################################################
##### Cross-table of statistical tasks vs performance measures #####
##################################################################

# get table of frequency and percentage of performance measures by statistical tasks 

cross_table <- survey %>%
  select(`3.3.estimandtarget_type`, `5.4.perfmeasures`) %>%
  # Separate rows based on the delimiters ";"
  separate_rows(`5.4.perfmeasures`, sep = ";|,") %>%
  # Clean up the Performance Measures column
  mutate(perfmeasures = str_trim(`5.4.perfmeasures`),
         perfmeasures = case_when(
           grepl("Bias", perfmeasures, ignore.case = TRUE) ~ "Bias",
           grepl("Mean squared error|MSE|relative standard error", perfmeasures, ignore.case = TRUE) ~ "Mean squared error (MSE)",
           grepl("Confidence interval length|width", perfmeasures, ignore.case = TRUE) ~ "Confidence interval width",
           grepl("Precision|coefficient of variation|Coefficient of variance", perfmeasures, ignore.case = TRUE) ~ "Precision",
           grepl("Power", perfmeasures, ignore.case = TRUE) ~ "Power",
           grepl("Type I|Type II", perfmeasures, ignore.case = TRUE) ~ "Type I or II error",
           grepl("false positive rate|false negative rate|TPR|TNR|FPR|FNR|classification rate|positive predictive value| misclassification|error rate", perfmeasures, ignore.case = TRUE) ~ "Classification rate",
           grepl("Coverage", perfmeasures, ignore.case = TRUE) ~ "Coverage",
           grepl("Accuracy", perfmeasures, ignore.case = TRUE) ~ "Not reported or unclear",
           TRUE ~ "Other"
         ),
         estimandtarget = case_when(
           grepl("Estimand", `3.3.estimandtarget_type`, ignore.case = TRUE) ~ "Estimand",
           grepl("Null hypothesis", `3.3.estimandtarget_type`, ignore.case = TRUE) ~ "Null hypothesis",
           grepl("Selected design", `3.3.estimandtarget_type`, ignore.case = TRUE) ~ "Study design",
           grepl("Predictions", `3.3.estimandtarget_type`, ignore.case = TRUE) ~ "Predictions",
           grepl("Model", `3.3.estimandtarget_type`, ignore.case = TRUE) ~ "Selected model",
           TRUE ~ "Other"
         )) %>%
  group_by(estimandtarget, perfmeasures) %>%
  summarise(counts = n(), .groups = 'drop') %>%
  # Calculate percentage within each Estimand/Statistical task
  group_by(estimandtarget) %>%
  mutate(percentage = counts / sum(counts) * 100) %>%
  ungroup() %>%
  arrange(estimandtarget, desc(counts))


```



**Coding stage**

`6.3.software_type` What software(s) was used to run the simulation study?

`6.5.software_Rpackage_name` If an R package was reported, detail which one(s)

`7.3.code_datagen_basedonprevious` Was the code of the data generating mechanism inspired or expanded from another simulation study code?

```{r}
###### 6: Software type
#table(survey$`6.3.software_type`)

# Software list
software_list <- survey$`6.3.software_type`

# get summary for just R across all articles
software_R <- data.frame(Software=software_list) %>%
  separate_rows(Software, sep = ";|,") %>% 
  mutate(Software = case_when(
           Software=="R" ~ "R",
           TRUE ~ "Other"
         ))

# Derive the counts and percentages
software_R_summary <- software_R %>%
  group_by(Software) %>%
  summarise(counts = n()) 


# get summary for combinations of software
software_dat <- data.frame(Software=software_list) %>%
  mutate(Software = case_when(
           Software=="R" ~ "R",
           grepl("JAGS|NIMBLE|R;Stan", Software, ignore.case = T) ~ "R with JAGS,\nNIMBLE or STAN",
           grepl("python", Software, ignore.case = T) ~ "Python",
           grepl("None", Software) ~ "Not reported",
           TRUE ~ "Other"
         ))

# Derive the counts and percentages
software_summary <- software_dat %>%
  group_by(Software) %>%
  summarise(counts = n()) %>%
  mutate(Percentage = counts / sum(counts) * 100) %>% 
  arrange(desc(counts)) %>%
  mutate(Software = factor(Software, levels = unique(Software))) 


# Plot histogram
ggplot(software_summary, aes(x = reorder(Software, counts), y = counts, fill = Software)) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal() +
  coord_flip()+
  scale_y_continuous(breaks = seq(0,75, by=10)) +
  labs(title = "Statistical software", x = "", y = "counts") +
  theme(axis.text.x = element_text(size=14)) +
  theme(axis.text.y = element_text(size=14)) +
  theme(legend.position = "none")




###### 6: Software R package
# super messy.... and not informative?
package_list <- unlist(strsplit(survey$`6.5.software_Rpackage_name`, ";|,"))
package_list <- data.frame(package_list)
kable(table(package_list), format="html")

```

```{r}
###### 7: Code
#survey$`7.3.code_datagen_basedonprevious`

# define colors
colors <- c("NA" = "grey", "No" = "#377eb8", "Yes" = "#4daf4a")


# make variable as factor
survey$`7.3.code_datagen_basedonprevious` <- factor(survey$`7.3.code_datagen_basedonprevious`,
                                                    levels = c("Yes", "No"))
survey$`7.3.code_datagen_basedonprevious` <- addNA(survey$`7.3.code_datagen_basedonprevious`,
                                                   ifany = TRUE)


# Make histogram
ggplot(survey, aes(x = `7.3.code_datagen_basedonprevious`, fill = `7.3.code_datagen_basedonprevious`)) +
  geom_bar(width = 0.7) +
  #coord_flip() + 
  labs(x = "Code based on previous study", y = "Count", fill = "Answer") + # Set or remove axis labels and legend title
  scale_fill_manual(values = colors) +
  scale_y_continuous(breaks = seq(0, 100, by = 10), limits = c(0, 100)) +
  theme_minimal() +
  theme(axis.text.x = element_text(size=14)) +
  theme(axis.text.y = element_text(size=14)) +
  theme(legend.position = "bottom")  


```

**Analysis stage**

`9.1.analysis_exploratory` Was a working example or case study conducted?

`11.1.analysis_montecarlo_uncertainty` Are Monte Carlo error quantified to assess the simulation uncertainty? (by running the same simulation under different number of random-number seeds)

```{r}
# yes/no questions - make function to create a horizontal histogram for a given variable
create_hist <- function(survey, variable_name) {
  # get variable from data
  data_to_plot <- survey %>%
    select(all_of(variable_name)) %>%
    count(.data[[variable_name]])

  # define colors
  colors <- c("No" = "#377eb8", "Yes" = "#4daf4a")

  # make histogram
  ggplot(data_to_plot, aes(x = n, y = fct_relevel(.data[[variable_name]], "Yes", "No"), fill = .data[[variable_name]])) +
    geom_bar(stat = "identity", position = "dodge", width = 0.7) +
    #coord_flip() +
    xlab("") +
    ylab("Count") +
    ggtitle("") +
    scale_x_continuous(breaks = seq(0, 100, by = 10), limits = c(0, 100)) +
    scale_fill_manual(values = colors) +
    labs(y = variable_name, x = "Count") +
    theme(axis.text.x = element_text(size=14)) +
    theme(axis.text.y = element_text(size=14)) +
    theme_minimal() +
    theme(legend.position = "bottom", aspect.ratio = 1/2) 
}

# get plots for each variable
create_hist(survey, "9.1.analysis_exploratory")
create_hist(survey, "11.1.analysis_montecarlo_uncertainty")
```

## Summarised count results

Summarised counts of all variables with categories in survey.

```{r}

# function to set up frequency table for each variable
create_frequency_table <- function(data, variable_name) {
  freq_table <- table(data[[variable_name]], useNA = "ifany")
  data.frame(
    Variable = variable_name,
    Category = names(freq_table),
    Count = as.vector(freq_table)
  )
}

# list of all variable names
variable_names <- c(
  "1.3.aims_purpose", "1.4.preregistration", "2.3.datagen_type", "2.4.datagen_informed",
  "2.7.3.datagen_simulationruns_justification", "4.3.method_type",
  "6.3.software_type", 
  "7.3.code_datagen_basedonprevious", "9.1.analysis_exploratory",
  "11.1.analysis_montecarlo_uncertainty", "1.1.aims_reporting",
  "2.1.datagen_reporting", "3.1.estimandtarget_reporting",
  "4.1.method_reporting", "5.1.perfmeasures_reporting",
  "5.3.perfmeasures_lessknown", "6.1.software_reporting",
  "6.4.software_Rpackage", "7.1.code_datagen",
  "7.2.code_datagen_allsteps", "8.1.code_perfmeasures",
  "10.1.analysis_perfmeasures_reporting", "1.2.aims_reportingsection",
  "2.2.datagen_reportingsection", "2.5.2.datagen_parameters_section",
  "2.6.2.datagen_conditions_section", "2.7.2.datagen_simulationruns_section",
  "3.2.estimandtarget_reportingsection", "4.2.method_reportingsection",
  "5.2.perfmeasures_reportingsection", "6.2.software_reportingsection",
  "9.2.analysis_exploratory_reporting", "10.2.analysis_perfmeasures_reportingsection",
  "11.2.analysis_montecarlo_reportingsection"
)

# make table with summary frequencies of all results
combined_table <- lapply(variable_names, create_frequency_table, data = survey) %>% 
  bind_rows()

# formatted table for output
kable_output <- kable(combined_table, format = "html", caption = "Count of simulation studies per category") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)

# colorrrs
colors <- rep(c("#EDFBD7", "white"),20)


# apply colors to rows
for (i in seq_along(variable_names)) {
  rows <- which(combined_table$Variable == variable_names[i])
  if(length(rows) > 0) {
    kable_output <- row_spec(kable_output, rows, background = colors[i %% length(colors) + 1])
  }
}

kable_output

```

## Reviewer agreement

```{r}
# load data
datcrosscheck <- read_excel("~/Projects/simsurvey/data/survey/simsurvey_crosscheck_summary.xlsx", na=c("", "NA", NA))

# make plot labels for survey questions
q_label <- c("18.aims reporting", "30.aims reporting section",
             "1.aims purpose", "2.preregistration",
             "19.datagen reporting","31.datagen reporting section",
             "3.datagen type", "4.datagen informed",
             "5.datagen parameters", "32.datagen parameters section",
             "6.datagen conditions", "33.datagen conditions section",
             "7.datagen simulation runs", "34.datagen simulationruns section",
             "8.datagen simulation runs justification", "9.datagen distribution",
             "20.estimand/target reporting", "35.estimand/target reporting section",
             "10.estimand/target type", "21.method literature reporting",
             "36.method lit reporting section", "11.method type",
             "22.perfmeasures reporting", "37.perf measures reporting section",
             "23.perfmeasures less known", "12.perf measures",
             "24.software reporting", "38.software reporting section",
             "13.software type", "25.software R package",
             "14.software R package name", "26.code datagen",
             "27.code datagen all steps", "15.code datagen based on previous",
             "28.code perf measures", "16.analysis exploratory",
             "39.analysis case study reporting section", "29.analysis perfmeasures reporting",
             "40.analysis perfmeasures reporting section", "17.analysis montecarlo uncertainty",
             "41.analysis montecarlo reporting section")


# make into factor and order chrononologically 
datcrosscheck$survey_question_label <- q_label
datcrosscheck$survey_question_label <- factor(datcrosscheck$survey_question_label,
                                              levels=rev(c("1.aims purpose", "2.preregistration","3.datagen type",
                                                       "4.datagen informed", "5.datagen parameters", "6.datagen conditions",
                                                       "7.datagen simulation runs", "8.datagen simulation runs justification",
                                                       "9.datagen distribution", "10.estimand/target type", "11.method type",
                                                       "12.perf measures", "13.software type", "14.software R package name",
                                                       "15.code datagen based on previous", "16.analysis exploratory",
                                                       "17.analysis montecarlo uncertainty", "18.aims reporting",
                                                       "19.datagen reporting", "20.estimand/target reporting", 
                                                       "21.method literature reporting", "22.perfmeasures reporting",
                                                       "23.perfmeasures less known", "24.software reporting",
                                                       "25.software R package", "26.code datagen", "27.code datagen all steps",
                                                       "28.code perf measures", "29.analysis perfmeasures reporting",
                                                       "30.aims reporting section", "31.datagen reporting section",
                                                       "32.datagen parameters section", "33.datagen conditions section",
                                                       "34.datagen simulationruns section", "35.estimand/target reporting section",
                                                       "36.method lit reporting section", "37.perf measures reporting section",
                                                       "38.software reporting section", "39.analysis case study reporting section",
                                                       "40.analysis perfmeasures reporting section", "41.analysis montecarlo reporting section")))



# get percentages
max_value <- max(datcrosscheck$crosscheck_agreement)
datcrosscheck$crosscheck_agreement_percent <- (datcrosscheck$crosscheck_agreement / max_value) * 100


# make lollipop plot of crosscheck agreement
p <- ggplot(datcrosscheck, aes(x = crosscheck_agreement_percent, y = survey_question_label)) +
  geom_segment(aes(x = 0,
                   xend = crosscheck_agreement_percent,
                   yend = survey_question_label), colour = "darkgray") +
  geom_point(colour = "deepskyblue3", size = 2) +
  labs(x = "Crosscheck Agreement (%)", y = "Survey Question") +
  coord_fixed(4) +
  theme_minimal()

print(p)

# save plot for manuscript
ggsave("output/crosscheck_agreement_lollipop.png", p,
       width = 8, height = 10, units = "in", bg="white", dpi = 400)


```


# References

Morris, T. P., White, I. R., & Crowther, M. J. (2019). Using simulation studies to evaluate statistical methods. Statistics in Medicine, 38(11), 2074--2102. <https://doi.org/10.1002/sim.8086>

R Core Team (2023). *R: A Language and Environment for Statistical Computing*. R Foundation for Statistical Computing, Vienna, Austria. <https://www.R-project.org/>.

# Session information {#session_info}

```{r Reproducibility-SessionInfo-R-environment, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", out.width='100%', results='asis'}

sessioninfo::session_info() %>%
  details::details(
    summary = 'Current session info',
    open    = F
  )

```
