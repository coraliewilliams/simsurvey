---
title: "Current Practices of Simulation Studies for Statistical Method Evaluation in Ecology and Evolutionary Biology"
author: "Coralie Williams, Malgorzata Lagisz, Kyle Morrison, Lorenzo Ricolfi, Yefeng Yang, David Warton, and Shinichi Nakagawa"
date: "Last compiled on `r format(Sys.time(), '%d %B, %Y')`"
format:
  html:
    toc: true
    toc-location: left
    toc-depth: 2
    theme: sandstone
    embed-resources: true
    code-fold: show
    code-tools: true
    number-sections: true
editor_options: 
  chunk_output_type: console
---

```{r setup}
#| output: false
#| warning: false
#| label: packages
#| code-overflow: wrap
#| code-fold: true

pacman::p_load(
  rmarkdown, readr, dplyr, purrr, splitstackshape, tidyverse, tidyr, ggplot2,
  vroom, details, sessioninfo, devtools, readxl, forcats, stringr
)

options(digits = 3, scipen = 5)
```

# Background

Simulation studies hold a central role in evaluating statistical methodologies. Conducting a simulation study is similar to an experiment. In a simulation study the underlying process of generating the data is known, and the statistical performance can be assessed under diverse scenarios. Here, we present the findings from a survey of 96 research articles in ecology and evolutionary biology journals that use at least one simulation study to evaluate statistical methods.

A framework called ADEMP (Aims, Data-generating mechanisms, Methods, Estimand/statistical target, Performance measures) was introduced by Morris et al. (2019, Stat Med, 38, p2074), and provides key steps to plan, code, analyse, and report simulation studies.

Using the ADEMP framework as a basis, we put together a list of reporting items to characterise and assess the reporting practices of simulation studies. Our results provide an overview of the current state of simulation studies in ecology and evolutionary biology.

# Objectives

Using the ADEMP+ framework we will:

-   Survey the characteristics of simulation studies evaluating statistical methodologies in ecology and evolutionary biology.

-   Assess the reporting practices of simulation studies evaluating statistical methodologies in ecology and evolutionary biology.

# Literature search

## Journal list

```{r journalList, warning=F, message=F}


# Load journal lists
jcr_stats <- read_csv("~/Projects/simsurvey/data/JCR/JCR_JournalResults_09_2022_Statistics_and_Probability.csv", skip = 2)
jcr_eco <- read_csv("~/Projects/simsurvey/data/JCR/JCR_JournalResults_09_2022_Ecology.csv", skip = 2)
jcr_evo <- read_csv("~/Projects/simsurvey/data/JCR/JCR_JournalResults_09_2022_Evolutionary_Biology.csv", skip = 2)

# Clean: delete empty rows and comment lines at the end of files
jcr_stats <- jcr_stats[which(!is.na(jcr_stats$ISSN)),]
jcr_eco <- jcr_eco[which(!is.na(jcr_eco$ISSN)),]
jcr_evo <- jcr_evo[which(!is.na(jcr_evo$ISSN)),]


# Check how many journals overlap between each journal group: none with stats journal list, and 18 journals between eco and evo
stats_in_eco <- jcr_stats[which(jcr_stats$`Journal name` %in% jcr_eco$`Journal name`),]
stats_in_evo <- jcr_stats[which(jcr_stats$`Journal name` %in% jcr_evo$`Journal name`),]
eco_in_evo <- jcr_eco$`Journal name`[which(jcr_eco$`Journal name` %in% jcr_evo$`Journal name`)]
evo_in_eco <- jcr_evo$`Journal name`[which(jcr_evo$`Journal name` %in% jcr_eco$`Journal name`)]

# get concatenated list of eco + evo journal lists
ecoevo <- rbind(jcr_eco, jcr_evo)

## change in code below on 20/09/2023, before this code was merging on all columns and only matched 15 journals and missed 3 journals that were overlapping due to different values in "JIF Quartile" column

# get list of matching and unique journals between eco and evo groups
ecoevo_match <- merge(jcr_eco[,-c(5,8)], jcr_evo[,-c(5,8)], by=c("Journal name","JCR Abbreviation", "ISSN", "eISSN", "Total Citations", "2021 JIF", "2021 JCI", "% of OA Gold"))
ecoevo_match$Category <- "Both"
ecoevo_match$`JIF Quartile` <- "NA"
ecoevo_notmatch <- ecoevo[which(!ecoevo$`Journal name` %in% ecoevo_match$`Journal name`),]


# get merged list of journals from eco and evo
ecoevo_merged <- rbind(ecoevo_match, ecoevo_notmatch)

# save results
write_csv(ecoevo_merged, "~/Projects/simsurvey/data/ecoevo_jcr_journal_list.csv", na="")

```

## Search strings

The custom search string was developed on 13/10/2022 on Web of Science

::: {.callout-tip appearance="minimal" icon="false"}
## **(TS=((simulation\*) AND ("method") AND ("compar" OR "evaluat" OR "validat" OR "statist") AND (bias OR coverag\* OR power OR convergence OR"standard error" OR "confidence interval" OR "performance measure" OR "mean error" OR "type I error"))) AND WC=("Ecology" OR "Evolutionary Biology"**
:::

## Inclusion and exclusion criteria

-   Include publications between 01-01-2012 and 01-09-2022.
-   Include studies using simulation for the evaluation of statistical methodologies. Simulation studies that are not assessing methods in statistics will be excluded (for example simulation studies to assess ecological theories: <https://doi.org/10.1016/j.ecolmodel.2019.02.007>).
-   Simulation studies that are part of a review, commentary, letter to the editor or tutorial will be excluded (for example: <https://doi.org/10.1111/2041-210X.1380>) Included studies published in one of predefined journals in Table 1.
-   Include if: Full text is available and full text is in English

::: column-margin
Note, exclusion term criteria were added post-hoc.
:::


# Data cleaning

```{r}
# Load text extraction
survey_raw <- read_excel("~/Projects/simsurvey/data/survey/simulationSurvey_extraction_103papers_21092023.xlsx", na=c("", "NA", NA))

# remove excluded papers
survey <- survey_raw %>% filter(is.na(exclude))

# remove questions that are comments
survey <- survey %>% select(!matches("comment"))

# names of reporting questions
r <- c("1.1.aims_reporting", 
       "2.1.datagen_reporting", 
       "3.1.estimandtarget_reporting",
       "4.1.method_reporting",
       "5.1.perfmeasures_reporting",
       "6.1.software_reporting",
       "9.1.analysis_exploratory",
       "10.1.analysis_perfmeasures_reporting",
       "11.1.analysis_montecarlo_uncertainty")

# names of reporting-section questions 
rs <- c("1.2.aims_reportingsection", 
        "2.2.datagen_reportingsection", 
        "3.2.estimandtarget_reportingsection",
        "4.2.method_reportingsection",
        "5.2.perfmeasures_reportingsection",
        "6.2.software_reportingsection",
        "9.2.analysis_exploratory_reporting",
        "10.2.analysis_perfmeasures_reportingsection",
        "10.1.analysis_perfmeasures_reporting",
        "11.2.analysis_montecarlo_reportingsection")

# characteristics questions
c <- c("")

```



# Analysis

### Reporting

```{r}

# pivot longer all questions of "reporting" type
r_long <- survey %>% 
  select(all_of(r)) %>%
  pivot_longer(cols = everything())

# Counting the occurrences of each category within each question
count_r <- r_long %>% 
  group_by(name, value) %>% 
  count()

# Get total number of occurrences for each question
count_r <- count_r %>% 
  group_by(name) %>% 
  mutate(total=sum(n))

# Calculate proportion and percentage
percent_r <- count_r %>% 
  mutate(proportion = n/total,
         percentage = proportion * 100)

# Format order of questions
percent_r$name <- factor(percent_r$name, levels=rev(r))
percent_r$value <- replace_na(percent_r$value, "missing")
percent_r$value <- factor(percent_r$value, levels=c("missing", "No", "Yes"))


# Creating the plot
fig1 <- ggplot(data = percent_r, aes(x = name, y = percentage, fill = value)) +
  geom_col(width = 0.7, color = "black") +
  coord_flip(ylim = c(0, 100)) +
  scale_fill_manual(values = c("#E3E3E3", "#713979", "#4DAF4A")) +
  theme(legend.position = "bottom", 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank()) +
  ylab("Percentage (%)") +
  xlab("Survey Question")
fig1

```



### Reporting section

```{r}

# pivot longer all questions of "reporting section" type
rs_long <- survey %>% 
  select(all_of(rs)) %>%
  pivot_longer(cols = everything())

# Counting the occurrences of each category within each question
count_rs <- rs_long %>% 
  group_by(name, value) %>% 
  count()

# Get total number of occurrences for each question
count_rs <- count_rs %>% 
  group_by(name) %>% 
  mutate(total=sum(n))

# Calculate proportion and percentage
percent_rs <- count_rs %>% 
  mutate(proportion = n/total,
         percentage = proportion * 100)

# Format order of questions
percent_rs$name <- factor(percent_rs$name, levels=rev(rs))
percent_rs$value <- replace_na(percent_rs$value, "missing")
percent_rs$value <- factor(percent_rs$value, levels=c("missing", "No", "Yes"))


# Creating the plot
fig2 <- ggplot(data = percent_rs, aes(x = name, y = percentage, fill = value)) +
  geom_col(width = 0.7, color = "black") +
  coord_flip(ylim = c(0, 100)) +
  scale_fill_manual(values = c("#E3E3E3", "#713979", "#4DAF4A")) +
  theme(legend.position = "bottom", 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank()) +
  ylab("Percentage (%)") +
  xlab("Survey Question")
fig2

```



### Characteristics

```{r}
# 
```









# Important points

### Example of MCMC studies

Example of papers including an analaysis using Monte Carlo Markov Chain (MCMC)

# References

Morris, T. P., White, I. R., & Crowther, M. J. (2019). Using simulation studies to evaluate statistical methods. Statistics in Medicine, 38(11), 2074--2102. <https://doi.org/10.1002/sim.8086>

# Session info

```{r Reproducibility-SessionInfo-R-environment, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", out.width='100%', results='asis'}

sessioninfo::session_info()%>%
  details::details(
    summary = 'Current session info',
    open    = TRUE
  )

```
